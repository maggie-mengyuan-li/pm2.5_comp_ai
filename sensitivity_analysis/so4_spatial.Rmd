---
title: "Additional sensitivity analyses: spatial models"
author: "Maggie Li (ml4424)"
date: "7/7/2021"
output: html_document
---

```{r load packages}
library(spdep)
library(rgdal)
library(rgeos)
library(tidyverse)
library(splm)
library(tmap)
library(tidycensus)
library(lme4)
library(gamm4)
```

```{r Read in data}
setwd('..') # set wd to one folder up, pm2.5_comp_ai master folder
# read in files, wrangle data to join with spatial dataset
so4 = read_csv("data/county_concentrations/joined_dta/so4_ai_join.csv") %>% 
  rename(GEOID = County) %>% 
  arrange((as.numeric(GEOID))) %>% 
  dplyr::select(GEOID, so4, State, year, county_type, popd_q, hhinc_q, Climate_Zone)
```

## Spatial Models with GAMM tensor term for spatial autocorrelation (geoadditive model)
Note to Vivian: If you don't have a census API key yet you can download it from here: https://api.census.gov/data/key_signup.html

Documentation for census_api_key: https://search.r-project.org/CRAN/refmans/tidycensus/html/census_api_key.html
```{r cache = TRUE}
## Get county shapefile and latitude longitude of county centroids for tensor smooth product term
census_api_key("ef9bc9f1392567620517b2f5ba86c86ebbd70d69", overwrite=TRUE, install = TRUE)
county <- get_decennial(
  geography = "county",
  variables = c(county = "COUNTY", state = "STATE"),
  output = "wide",
  geometry = TRUE
  ) %>% 
  filter(state != "2" & state != "15" & state <= 56) %>% # filter out AL and HI, and territories
  mutate(GEOID = str_replace(GEOID, "46113", "46102")) %>% 
  filter(GEOID != "51515")

# compare w/ us_counties df
# county$GEOID
# us_counties$GEOID
# setdiff(county$GEOID, us_counties$GEOID) #compare these vectors
# setdiff(us_counties$GEOID, county$GEOID) # NOTES: Oglala County (46102) was renamed from Shannon County (46113) in 2015; Bedford City (51515) joined Bedford County in 2013 (51019); so use str_replace to change to 46102 and drop 51515 FIPS

count_centroid <- county %>% 
  st_centroid()
# count_centroid
# st_coordinates(count_centroid$geometry) # this function extracts lat long but into a vector, not what we want

count_centroid <- count_centroid %>% 
  mutate(long = sf::st_coordinates(.)[,1],
         lat = sf::st_coordinates(.)[,1]) # extract centroid lat long from sf into the same df. yay!
count_centroid
# Join county lat lon data with SO4
so4
so4_lat_lon = left_join(so4, count_centroid)
so4_lat_lon
```

## Main effects only (no county type x year interX term): reported in Table 2 under "Adjusted for Latitude/Longitude"

```{r 10 knots}
# Run GAMM with tensor smooth term
so4_tensor_mod =  gamm4(so4 ~ county_type + as.factor(year) + popd_q + hhinc_q
                        + t2(lat, long,
                             k = c(10, 10), # try default k knots first
                             bs = 'cr'),
                 random =~(1|State/GEOID),
                 data = so4_lat_lon)

summary(so4_tensor_mod$gam)
summary(so4_tensor_mod$mer)
# save model output as RDS to read back in later
saveRDS(so4_tensor_mod,
        file = "../intermediate/model_outputs/spatial/main_effects_only/so4_tensor_10knots.rds")
so4_tensor_mod = readRDS("../intermediate/model_outputs/spatial/main_effects_only/so4_tensor_10knots.rds")

summary(so4_tensor_mod$mer)
# Double check coefficient
summary(so4_tensor_mod$mer)$coefficients[2,1]

# Double check SEs
summary(so4_tensor_mod$mer)$coefficients[2,2]


## Extract 95% CI: point estimate, LL, UL
paste(summary(so4_tensor_mod$mer)$coefficients[2,1] %>% round(digits = 3),
      " (",
      round(summary(so4_tensor_mod$mer)$coefficients[2,1] - 1.96*summary(so4_tensor_mod$mer)$coefficients[2,2], digits = 3),
      ", ",
      round(summary(so4_tensor_mod$mer)$coefficients[2,1] + 1.96*summary(so4_tensor_mod$mer)$coefficients[2,2], digits = 3),
      ")", sep = "")
paste(summary(so4_tensor_mod$mer)$coefficients[2,1] %>% round(digits = 2),
      " (",
      round(summary(so4_tensor_mod$mer)$coefficients[2,1] - 1.96*summary(so4_tensor_mod$mer)$coefficients[2,2], digits = 2),
      ", ",
      round(summary(so4_tensor_mod$mer)$coefficients[2,1] + 1.96*summary(so4_tensor_mod$mer)$coefficients[2,2], digits = 2),
      ")", sep = "")

```
## With county type x year interX term: reported in Supplementary Figure S5

###### GAMM4 t2 Difference in time trends plot
```{r run GAMM with 10 knots}
# # Run GAMM with tensor smooth term
# so4_tensor_mod =  gamm4(so4 ~ county_type*as.factor(year) + popd_q + hhinc_q
#                         + t2(lat, long,
#                              k = c(10, 10),
#                              bs = 'cr'),
#                  random =~(1|State/GEOID),
#                  data = so4_lat_lon) # try default k knotes first
# 
# summary(so4_tensor_mod$gam)
# # save model output as RDS to read back in later
# saveRDS(so4_tensor_mod,
#         file = "../intermediate/model_outputs/spatial/so4_tensor_10knots.rds")
so4_tensor_mod = readRDS("../intermediate/model_outputs/spatial/so4_tensor_10knots.rds")
so4_tensor_mod
summary(so4_tensor_mod$gam)

# summary(so4_kkp_interx) # compare the two model summaries spml vs. gamm4 t2
```


```{r plot changes in NO3 diff by county type over time}
# vcov matrix
native_yr_vcov <- vcov(so4_tensor_mod$gam)[c(2,seq(38,54)), c(2,seq(38,54))]
# calculate all the variances for all the years i.e. var(x+y); should be 18 total entries
var_vector = c()
for (i in 2:18){
  var_vector[1] <- native_yr_vcov[1,1]
  var_vector[i] <- native_yr_vcov[1,1] + native_yr_vcov[i,i] + 2 * native_yr_vcov[i,1]
}
native_yr_vcov[1,1] + native_yr_vcov[2,2] + 2 * native_yr_vcov[2,1]

length(unique(native_yr_vcov))
sd_vector <- sqrt(var_vector)

#matrix with 19 cols for 19 years, three rows: one for effect estimate of total effect per year (total effect = main effect + interx effect), one for CI lower, one for CI upper
so4_decline_model_all <- data.frame()
so4_decline_model_all[1,1] <- summary(so4_tensor_mod$gam)$p.coeff[2] # county type main effect estimate (baseline year)
so4_decline_model_all[1,2] <- summary(so4_tensor_mod$gam)$p.coeff[2] - 1.96*sd_vector[1] # LL 95% CI
so4_decline_model_all[1,3] <- summary(so4_tensor_mod$gam)$p.coeff[2] + 1.96*sd_vector[1] # UL 95% CI


names(summary(so4_tensor_mod$gam))
summary(so4_tensor_mod$gam)
summary(so4_tensor_mod$gam)[1]
summary(so4_tensor_mod$gam)$p.coeff[38]

# fill in matrix thru loop for every following year
yr_ct <- 38
for (i in 2:18){
  so4_decline_model_all[i,1] <- summary(so4_tensor_mod$gam)$p.coeff[2]+
    summary(so4_tensor_mod$gam)$p.coeff[yr_ct]
  so4_decline_model_all[i,2] <- summary(so4_tensor_mod$gam)$p.coeff[2]+
    summary(so4_tensor_mod$gam)$p.coeff[yr_ct] - 1.96*sd_vector[i]
  so4_decline_model_all[i,3] <- summary(so4_tensor_mod$gam)$p.coeff[2]+
    summary(so4_tensor_mod$gam)$p.coeff[yr_ct] + 1.96*sd_vector[i]
  yr_ct <- yr_ct + 1
}
# set col names
colnames(so4_decline_model_all) <- c('estimate', 'cl_lower', 'cl_upper')
so4_decline_model_all$year <- seq(2000, 2017)

#PLOT OF TOTAL EFFECT OF NATIVE OVER TIME
modelsp_interx_plot <-ggplot() + 
  theme_linedraw() + 
  geom_line(data = so4_decline_model_all,
            aes(x=year, y = estimate)) +
  geom_line(data=so4_decline_model_all,
            aes(x=year, y=cl_lower), linetype = "dashed") +
    geom_line(data=so4_decline_model_all,
            aes(x=year, y=cl_upper), linetype = "dashed") +
  ylim(-0.5, 0.62) +
  # ggtitle(expression(paste("Modeled ", PM[2.5], " Difference in AI vs. Non-AI Populated Counties"))) +
  ylab(expression(paste("Mean Difference in ", SO[4]^{"2-"}, " (", mu, "g/", m^3, ")"))) +
  xlab("Year") +
  theme(plot.title = element_text(size = 18),
        axis.title = element_text(size = 16),
        axis.text = element_text(size = 12),
        axis.title.x = element_blank(),
        # axis.title.y = element_blank()
        ) +
  guides(x =  guide_axis(angle = 45)) +
  scale_x_continuous(breaks = seq(2000,2018,1), expand = c(0, 0)) + 
  scale_y_continuous(breaks=seq(-0.5,0.5, by=0.5)) +
  geom_hline(yintercept=0, linetype="solid", color = "red") 
modelsp_interx_plot
ggsave("../figures/effectmod_plots/sensitivity/spatial/so4_interx_t2_10knots.png")
```


# 1. Spatial Lag Models (not using in our present analysis as of 11/1/22)
Get data in spatial df (so4_sp), create Queen's contiguity spatial weights matrix (w, wm, rwm)

## 6/21/2022 USE SO4 AS EXAMPLE MODEL_PM DATA

```{r read in spatial dataset, join with pm components data}

# # read in sf counties file from tigris library; filter out HI, AK, territories
# library(tigris)
# us_counties = counties() %>% filter(STATEFP != "02" & STATEFP != "15" & STATEFP <= 56)
# us_counties
# # convert sf to spdf to join with PM df
# us_counties_sp = as_Spatial(us_counties)
# 
# # select only model pm2.5 data from 2000
# so4_2000 = so4 %>% filter(year == 2000)
# so4_2000
# 
# # join PM data with spatial dataset to create spatial df for 2000
# so4_2000_sp <- merge(us_counties_sp, so4_2000)
# 
# # create spatial weights matrix
# w_v2 <- poly2nb(so4_2000_sp, queen = TRUE)
# summary(w_v2)
# 
# anti_join(st_drop_geometry(us_counties), so4_2000) # check that they contain same counties (even if out of order)
# 
# # check on bordering counties of given county
# w_v2[[730]]
# so4_2000_sp$GEOID[730] # random county of interest: champaign county, OH
# so4_2000_sp$GEOID[c(516, 877, 925, 2510, 2768, 2993)] # check to see if they are actually bordering counties; they are
# 
# # convert to matrix and then listw format
# # zero.policy = T to include island counties (offshore, but still a part of contiguous US state)
# wm <- nb2mat(w_v2, style='B', zero.policy = TRUE)
# rwm <- mat2listw(wm, style='W')
```

## Run spatial diagnostics on non-spatial models
```{r OLS regression}
# fit_1 <- lm(so4 ~ county_type + popd_q + hhinc_q,
#             data=so4_2000_sp)
# summary(fit_1)
# 
# # check global moran's I test of residuals
# lm.morantest(fit_1, rwm, alternative="two.sided",  zero.policy = TRUE)
# 
# # check local moran's I test of residuals
# 
# # NOTES: Global Moran's I value is significant; should proceed with spatial model
# 
# # run lagrange test as diagnostic for SLM or SEM
# lm.LMtests(fit_1, rwm, test = c("LMerr","LMlag","RLMerr","RLMlag","SARMA"),
#            zero.policy = TRUE)
# # NOTES: All p-values are highly significant in the standard and robust tests, ie. both spatial lag and error LM are significant (can run either model)
```

```{r linear mixed effects regression}
# library(lme4)
# 
# # get lat lon of us county centroids (projection = NAD83)
# library(rgeos)
# us_counties = st_read("../data/cb_2018_us_county_500k/cb_2018_us_county_500k.shp") %>%
#   filter(STATEFP != "02" & STATEFP != "15" & STATEFP <= 56) #filter to 48 contiguous states
# # calculate centroid
# sf_centroid = st_centroid(us_counties)
# # plot
# ggplot() +
#   geom_sf(data = us_counties, fill = 'white') +
#   geom_sf(data = sf_centroid, color = 'red')
# sf_centroid
# 
# # join centroid point and model PM data!
# so4_sf = merge(sf_centroid, so4)
# 
# # separate x and y coordinates, append these columns to dataframe
# so4_sf = so4_sf %>%
#   mutate(x = st_coordinates(so4_sf)[,1],
#          y = st_coordinates(so4_sf)[,2])
# 
# # run linear random intercept model
# nre_fit = lmer(so4 ~ county_type * as.factor(year) +
#                     popd_q + 
#                     hhinc_q +
#                     (1|State/GEOID),
#                   data = so4, REML=FALSE)
# summary(nre_fit)
# residuals(nre_fit)
# # create column for residual values in model PM dataframe
# so4$lmerres = residuals(nre_fit)
# so4
```

```{r cache = TRUE}
# # Run local moran's I on residuals
# 
# # filter out df with lmer residuals to just 2017 values
# so4_17_res = so4 %>% filter(year == 2017)
# # join PM data with spatial dataset to create spatial df for 2017
# so4_2017_lmer_sp <- merge(us_counties_sp, so4_17_res)
# 
# # Local moran's I of lmer residuals
# moran.plot(so4_2017_lmer_sp$so4, rwm)
# 
# # calculate local moran's I test of residuals
# local_lmer_17 <- localmoran(x = so4_2017_lmer_sp$so4, listw = rwm)
# 
# # binds results to our polygon shapefile
# moran.map_lmer_17 <- cbind(so4_2017_lmer_sp, local_lmer_17)
# 
# class(moran.map_lmer_17)
# tm_shape(moran.map_lmer_17) +
#   tm_fill(col = "Ii", # local moran's I statistic values
#           style = "quantile",
#           title = "local moran statistic") 
```

```{r Map hot and cold spots based on local morans I, cache = TRUE}
# # scale PM2.5
# so4_2017_lmer_sp$s_pm25 = scale(so4_2017_lmer_sp$so4) %>% as.vector()
# 
# #create a spatial lag variable for scaled pm2.5 and save it to a new column
# so4_2017_lmer_sp$lag_s_pm25 <- lag.listw(rwm, so4_2017_lmer_sp$s_pm25) # use 'rwm' listw weights object specified above to create lagged vector
# summary(so4_2017_lmer_sp$s_pm25)
# summary(so4_2017_lmer_sp$lag_s_pm25)
# 
# x <- so4_2017_lmer_sp$s_pm25
# y <- so4_2017_lmer_sp$lag_s_pm25
# xx <- tibble(x,y)
# moran.plot(x, rwm) # same as scatterplot above (just rescaled)
# names(so4_2017_lmer_sp)
# so4_2017_lmer_sp$lmerres
# # add column to show LISA quadrants
# so4_2017_lmer_sf <- st_as_sf(so4_2017_lmer_sp) %>% 
#   mutate(quad_sig = ifelse(so4_2017_lmer_sp$s_pm25 > 0 & 
#                               so4_2017_lmer_sp$lag_s_pm25 > 0 & 
#                               local_lmer_17[,5] <= 0.05, 
#                      "high-high",
#                      ifelse(so4_2017_lmer_sp$s_pm25 <= 0 & 
#                               so4_2017_lmer_sp$lag_s_pm25 <= 0 & 
#                               local_lmer_17[,5] <= 0.05, 
#                      "low-low", 
#                      ifelse(so4_2017_lmer_sp$s_pm25 > 0 & 
#                               so4_2017_lmer_sp$lag_s_pm25 <= 0 & 
#                               local_lmer_17[,5] <= 0.05, 
#                      "high-low",
#                      ifelse(so4_2017_lmer_sp$s_pm25 <= 0 & 
#                               so4_2017_lmer_sp$lag_s_pm25 > 0 & 
#                               local_lmer_17[,5] <= 0.05,
#                      "low-high", 
#                      "non-significant")))))
# table(so4_2017_lmer_sf$quad_sig)
# 
# # check that all h-h l-l from table() sum up to all significant counties
# nrow(local_lmer_17[local_lmer_17[,5] <= 0.05,])
# 
# qtm(so4_2017_lmer_sf, fill="quad_sig", fill.title="LISA")

```

```{r}
# # DUMMY CODE: calculate moran's I
# library(DHARMa)
# # It's a good idea to use a RE to take out the cluster effects. This accounts
# # for the autocorrelation within clusters 
# 
# # DHARMa default is to re-simulted REs - this means spatial pattern remains
# # because residuals are still clustered
# 
# res = simulateResiduals(nre_fit)
# # testSpatialAutocorrelation(res, x =  so4_sf$x, y = so4_sf$y) DOESN'T WORK, need to group by county to account for clustering within county over time
# 
# # However, it should disappear if you just calculate an aggregate residuals per cluster
# # Because at least how the data are simulated, cluster are spatially independent
# # Group by County
# res2 = recalculateResiduals(res, group = so4_sf$GEOID)
# testSpatialAutocorrelation(res2, 
#                            x =  aggregate(so4_sf$x, list(so4_sf$GEOID), mean)$x, 
#                            y = aggregate(so4_sf$y, list(so4_sf$GEOID), mean)$x)
# # Group by State
# res3 = recalculateResiduals(res, group = so4_sf$STATEFP)
# testSpatialAutocorrelation(res3, 
#                            x =  aggregate(so4_sf$x, list(so4_sf$STATEFP), mean)$x, 
#                            y = aggregate(so4_sf$y, list(so4_sf$STATEFP), mean)$x)
# 
# ## Conclusion, most counties are not spatially independent (significant moran's I values prevalent)
```

## Spatial Models using spatial reg package

```{r spatial lag model}
# library(spatialreg)
# fit_1_lag <- lagsarlm(so4 ~ county_type + popd_q + hhinc_q,
#             data=so4_2000_sp, rwm, zero.policy = TRUE)
# summary(fit_1_lag)
```

```{r spatial error model}
# fit_1_err <- errorsarlm(so4 ~ county_type + popd_q + hhinc_q,
#                         data=so4_2000_sp, rwm, zero.policy = TRUE)
# summary(fit_1_err)

```

## Spatial Models using splm package

```{r "transform data frame into panel data"}
# library(plm)
# 
# # convert df to panel dataframe
# p.data = pdata.frame(so4, index = c("GEOID", "year"))
# p.data

# # run splm model with queen's contiguity matrix, KKP specified random effects
# so4_nrelag = spml(so4 ~ county_type + popd_q + hhinc_q + year,
#                          data = p.data,
#                          index = c("GEOID", "year"),
#                          listw = rwm,
#                          model = "random",
#                          effect = "individual",
#                          lag = T,
#                          spatial.error = "kkp",
#                          zero.policy = TRUE)
# summary(so4_nrelag)
# 
# # save model output to intermediate folder
# saveRDS(so4_nrelag, file = "intermediate/spatial_models/splag_re_kkp_model.rds")

# # run splm model with queen's contiguity matrix, Baltagi specified random effects
# so4_nrelag_b = spml(so4 ~ county_type + popd_q + hhinc_q + year,
#                          data = p.data,
#                          index = c("GEOID", "year"),
#                          listw = rwm,
#                          model = "random",
#                          effect = "individual",
#                          lag = T,
#                          spatial.error = "kkp",
#                          zero.policy = TRUE)
# summary(so4_nrelag_b)
# 
# # save model output to intermediate folder
# saveRDS(so4_nrelag_b, file = "intermediate/spatial_models/splag_re_b_model.rds")

```

### Run spatial and non-spatial models; examine only recent years, after 2015

```{r}
# # convert df to panel dataframe
# so4_2015.2019 = so4 %>% filter(year >= 2015)
# p.data.2015.2019 = pdata.frame(so4_2015.2019, index = c("GEOID", "year"))
# p.data.2015.2019
# 
# lme_2015.2019 <- lmer(so4 ~ county_type + year +
#                     popd_q + 
#                     hhinc_q +
#                     county_type*year +
#                     (1|State/GEOID),
#                   data = so4_2015.2019, REML=FALSE)
# summary(lme_2015.2019)

# run splm model with queen's contiguity matrix, KKP specified random effects
# so4_kkp_2015.2019 = spml(so4 ~ county_type*year + popd_q + hhinc_q,
#                          data = p.data.2015.2019,
#                          index = c("GEOID", "year"),
#                          listw = rwm,
#                          model = "random",
#                          effect = "individual",
#                          lag = T,
#                          spatial.error = "kkp",
#                          zero.policy = TRUE)
# summary(so4_kkp_2015.2019)

```


### All Years: Run nonspatial and spatial models
#### Non spatial model
```{r}
# so4_lme <- lmer(so4 ~ county_type*as.factor(year) +
#                     popd_q + 
#                     hhinc_q +
#                     (1|State/GEOID),
#                   data = so4, REML=FALSE)
# summary(so4_lme)
# dim(model.matrix(so4_lme)) 
```
#### Spatial models (w/ contiguity based spatial weights matrix)

##### Without interX
```{r cache = TRUE}
# # run splm model with queen's contiguity matrix, KKP specified random effects
# so4_kkp = spml(so4 ~ county_type + year + popd_q + hhinc_q,
#                          data = p.data,
#                          index = c("GEOID", "year"),
#                          listw = rwm,
#                          model = "random",
#                          effect = "individual",
#                          lag = T,
#                          spatial.error = "kkp",
#                          zero.policy = TRUE)
# summary(so4_kkp)
# 
# # splag = readRDS("intermediate/spatial_models/splag_re_b_model.rds")
# # splag
```


##### With interX
```{r cache = TRUE}
# # run splm model with queen's contiguity matrix, KKP specified random effects, interX between county type and year
# # V1
# so4_kkp_interx = spml(so4 ~ county_type*year + popd_q + hhinc_q,
#                          data = p.data,
#                          index = c("GEOID", "year"),
#                          listw = rwm,
#                          model = "random",
#                          effect = "individual",
#                          lag = T,
#                          spatial.error = "kkp",
#                          zero.policy = TRUE)
# summary(so4_kkp_interx)

```

```{r}
# data("Produc", package = "Ecdat")
# class(Produc)
# class(p.data)
# data("usaww")
```


```{r run spml on simple df instead of panel df}
# so4_kkp_interx_df = spml(so4 ~ county_type*year + popd_q + hhinc_q,
#                          data = so4,
#                          index = c("GEOID", "year"),
#                          listw = rwm,
#                          model = "random",
#                          effect = "individual",
#                          lag = T,
#                          spatial.error = "kkp",
#                          zero.policy = TRUE)
# summary(so4_kkp_interx_df)
```


```{r cache = TRUE}
# # V2
# so4_kkp_interx_v2 = spml(so4 ~ county_type*year + popd_q + hhinc_q,
#                          data = p.data,
#                          index = c("year", "GEOID"), # reverse this from V1 above
#                          listw = rwm,
#                          model = "random",
#                          effect = "individual",
#                          lag = T,
#                          spatial.error = "kkp",
#                          zero.policy = TRUE)
# summary(so4_kkp_interx_v2)
```


###### SPML Difference in time trends plot
```{r}
# # vcov matrix
# native_yr_vcov <- vcov(so4_kkp_interx)[c(2,seq(38,54)), c(2,seq(38,54))]
# # calculate all the variances for all the years i.e. var(x+y); should be 18 total entries
# var_vector = c()
# for (i in 2:18){
#   var_vector[1] <- native_yr_vcov[1,1]
#   var_vector[i] <- native_yr_vcov[1,1] + native_yr_vcov[i,i] + 2 * native_yr_vcov[i,1]
# }
# native_yr_vcov[1,1] + native_yr_vcov[2,2] + 2 * native_yr_vcov[2,1]
# length(unique(native_yr_vcov))
# sd_vector <- sqrt(var_vector)
# 
# #matrix with 19 cols for 19 years, three rows: one for effect estimate of total effect per year (total effect = main effect + interx effect), one for CI lower, one for CI upper
# so4_decline_model_all <- data.frame()
# so4_decline_model_all[1,1] <- summary(so4_kkp_interx)$coefficients[2] # county type main effect estimate (baseline year)
# so4_decline_model_all[1,2] <- summary(so4_kkp_interx)$coefficients[2] - 1.96*sd_vector[1] # LL 95% CI
# so4_decline_model_all[1,3] <- summary(so4_kkp_interx)$coefficients[2] + 1.96*sd_vector[1] # UL 95% CI
# names(summary(so4_kkp_interx))
# summary(so4_kkp_interx)
# 
# # fill in matrix thru loop for every following year
# yr_ct <- 38
# for (i in 2:18){
#   so4_decline_model_all[i,1] <- summary(so4_kkp_interx)$coefficients[2]+
#     summary(so4_kkp_interx)$coefficients[yr_ct]
#   so4_decline_model_all[i,2] <- summary(so4_kkp_interx)$coefficients[2]+
#     summary(so4_kkp_interx)$coefficients[yr_ct] - 1.96*sd_vector[i]
#   so4_decline_model_all[i,3] <- summary(so4_kkp_interx)$coefficients[2]+
#     summary(so4_kkp_interx)$coefficients[yr_ct] + 1.96*sd_vector[i]
#   yr_ct <- yr_ct + 1
# }
# # set col names
# colnames(so4_decline_model_all) <- c('estimate', 'cl_lower', 'cl_upper')
# so4_decline_model_all$year <- seq(2000, 2017)
# 
# #PLOT OF TOTAL EFFECT OF NATIVE OVER TIME
# modelsp_interx_plot <-ggplot() + 
#   theme_linedraw() + 
#   geom_line(data = so4_decline_model_all,
#             aes(x=year, y = estimate)) +
#   geom_line(data=so4_decline_model_all,
#             aes(x=year, y=cl_lower), linetype = "dashed") +
#     geom_line(data=so4_decline_model_all,
#             aes(x=year, y=cl_upper), linetype = "dashed") +
#   ylim(-1, 0.5) +
#   # ggtitle(expression(paste("Modeled ", PM[2.5], " Difference in AI vs. Non-AI Populated Counties"))) +
#   ylab(expression(paste("Mean Difference in ", SO[4]{"2-"}, " (", mu, "g/", m^3, ")"))) +
#   xlab("Year") +
#   theme(plot.title = element_text(size = 18),
#         axis.title = element_text(size = 16),
#         axis.text = element_text(size = 12),
#         # axis.title.x = element_blank(),
#         # axis.title.y = element_blank()
#         ) +
#   guides(x =  guide_axis(angle = 45)) +
#   scale_x_continuous(breaks = seq(2000,2018,1), expand = c(0, 0)) + 
#   geom_hline(yintercept=0, linetype="solid", color = "red") 
# modelsp_interx_plot
# ggsave("../figures/effectmod_plots/sensitivity/spatial/so4_interx_spatial.png")
```

#### Spatial models (w/ distance based spatial weights matrix)

```{r}
# # create distance based matrix
# library(fields)
# so4_2000_sp
# mycoords <- coordinates(so4_2000_sp) # creates xy coords of all 3107 counties
# length(mycoords)                         # should be 6214 (3107*2)
# mydm <- rdist.earth(mycoords)            # computes distance in miles!
# for(i in 1:dim(mydm)[1]) {mydm[i,i] = 0} # renders exactly zero all diagonal elements
# mydm[mydm > 1000] <- 0                   # all distances > 1000 miles are set to zero
# mydm <- ifelse(mydm!=0, 1/mydm, mydm)    # inverting distances
# mydm.lw <- mat2listw(mydm, style="W")    # create a (normalized) listw object
# mydmi <- listw2mat(mydm.lw)              # change back to 'classic' matrix, if desired
# View(mydm.lw)
# 
# w_v2[[730]]
# so4_2000_sp$GEOID[730]
# so4_2000_sp$GEOID[c(334, 1668, 1680, 1851, 1901, 2099, 2657)]
# 
# # run spatial model with inverse distance based matrix
# so4_kkp_interx_idm = spml(so4 ~ county_type*year + popd_q + hhinc_q,
#                          data = p.data,
#                          index = c("year", "GEOID"), # reverse this from V1 above
#                          listw = mydm.lw,
#                          model = "random",
#                          effect = "individual",
#                          lag = T,
#                          spatial.error = "kkp",
#                          zero.policy = TRUE)
# summary(so4_kkp_interx_idm)
```
