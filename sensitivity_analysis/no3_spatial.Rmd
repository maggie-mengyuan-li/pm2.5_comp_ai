---
title: "Additional sensitivity analyses: spatial models"
author: "Maggie Li (ml4424)"
date: "7/7/2021"
output: html_document
---

```{r}
library(knitr)
knitr::opts_chunk$set(warning = FALSE, 
                      message = FALSE, cache.lazy = FALSE)
```

```{r load packages}
library(spdep)
library(rgdal)
library(rgeos)
library(tidyverse)
library(tidycensus)
library(splm)
library(tmap)
library(lme4)
library(gamm4)
```

```{r Read in data}
setwd('..') # set wd to one folder up, pm2.5_comp_ai master folder
# read in files, wrangle data to join with spatial dataset
no3 = read_csv("data/county_concentrations/joined_dta/no3_ai_join.csv") %>%
  rename(GEOID = County) %>%
  arrange((as.numeric(GEOID))) %>%
  dplyr::select(GEOID, no3, State, year, county_type, popd_q, hhinc_q, Climate_Zone)
```

# Geoadditive Models with GAMM tensor term to account for spatial autocorrelation

## Get county shapefile and latitude longitude of county centroids
Note to Vivian: If you don't have a census API key yet you can download it from here: https://api.census.gov/data/key_signup.html

Documentation for census_api_key: https://search.r-project.org/CRAN/refmans/tidycensus/html/census_api_key.html

```{r cache = TRUE}
# get county centroid lat/lon coordinates for tensor smooth product term
census_api_key("ef9bc9f1392567620517b2f5ba86c86ebbd70d69", overwrite=TRUE, install = TRUE)
readRenviron("~/.Renviron")
county <- get_decennial(
  geography = "county",
  variables = c(county = "COUNTY", state = "STATE"),
  output = "wide",
  geometry = TRUE
  ) %>% 
  filter(state != "2" & state != "15" & state <= 56) %>% # filter out AL and HI, and territories
  mutate(GEOID = str_replace(GEOID, "46113", "46102")) %>% 
  filter(GEOID != "51515")

# compare w/ us_counties df
# county$GEOID
# us_counties$GEOID
# setdiff(county$GEOID, us_counties$GEOID) #compare these vectors
# setdiff(us_counties$GEOID, county$GEOID) 

# NOTES: Oglala County (46102) was renamed from Shannon County (46113) in 2015; Bedford City (51515) joined Bedford County in 2013 (51019); so use str_replace to change to 46102 and drop 51515 FIPS

count_centroid <- county %>% 
  st_centroid()
# count_centroid
# st_coordinates(count_centroid$geometry) # this function extracts lat long but into a vector, not what we want

count_centroid <- count_centroid %>% 
  mutate(long = sf::st_coordinates(.)[,1],
         lat = sf::st_coordinates(.)[,2]) # extract centroid lat long from sf into the same df. yay!

# Join county lat lon data with no3
no3_lat_lon = left_join(no3, count_centroid)

```

## Main effects only (no county type x year interX term): reported in Table 2 under "Adjusted for Latitude/Longitude"

```{r 10 knots}
# # Run GAMM with tensor smooth term
# no3_tensor_mod =  gamm4(no3 ~ county_type + as.factor(year) + popd_q + hhinc_q
#                         + t2(lat, long,
#                              k = c(10, 10), # default 10 knots
#                              bs = 'cr'),
#                  random =~(1|State/GEOID),
#                  data = no3_lat_lon) 
# 
# summary(no3_tensor_mod$gam)
# summary(no3_tensor_mod$mer)
# # save model output as RDS to read back in later
# saveRDS(no3_tensor_mod,
#         file = "../intermediate/model_outputs/spatial/main_effects_only/no3_tensor_10knots.rds")
no3_tensor_mod = readRDS("../intermediate/model_outputs/spatial/main_effects_only/no3_tensor_10knots.rds")

summary(no3_tensor_mod$mer)
# Double check coefficient
summary(no3_tensor_mod$mer)$coefficients[2,1]

# Double check SEs
summary(no3_tensor_mod$mer)$coefficients[2,2]


## Extract 95% CI: point estimate, LL, UL
paste(summary(no3_tensor_mod$mer)$coefficients[2,1] %>% round(digits = 3),
      " (",
      round(summary(no3_tensor_mod$mer)$coefficients[2,1] - 1.96*summary(no3_tensor_mod$mer)$coefficients[2,2], digits = 3),
      ", ",
      round(summary(no3_tensor_mod$mer)$coefficients[2,1] + 1.96*summary(no3_tensor_mod$mer)$coefficients[2,2], digits = 3),
      ")", sep = "")
paste(summary(no3_tensor_mod$mer)$coefficients[2,1] %>% round(digits = 2),
      " (",
      round(summary(no3_tensor_mod$mer)$coefficients[2,1] - 1.96*summary(no3_tensor_mod$mer)$coefficients[2,2], digits = 2),
      ", ",
      round(summary(no3_tensor_mod$mer)$coefficients[2,1] + 1.96*summary(no3_tensor_mod$mer)$coefficients[2,2], digits = 2),
      ")", sep = "")
```

## With county type x year interX term: reported in Supplementary Figure S5

###### GAMM4 t2 Difference in time trends plot

```{r run GAMM with 10 knots}
# Run GAMM with tensor smooth term
# no3_tensor_mod =  gamm4(no3 ~ county_type*as.factor(year) + popd_q + hhinc_q
#                         + t2(lat, long, 
#                              k = c(10, 10),
#                              bs = 'cr'),
#                  random =~(1|State/GEOID),
#                  data = no3_lat_lon) # try default k knotes first
# 
# summary(no3_tensor_mod$gam)

# # save model output as RDS to read back in later
# saveRDS(no3_tensor_mod,
#         file = "../intermediate/model_outputs/spatial/no3_tensor_10knots.rds")
no3_tensor_mod = readRDS("../intermediate/model_outputs/spatial/no3_tensor_10knots.rds")
no3_tensor_mod
summary(no3_tensor_mod$gam)

# summary(no3_kkp_interx) # compare the two model summaries spml vs. gamm4 t2
```

```{r plot changes in NO3 diff by county type over time}
# vcov matrix
native_yr_vcov <- vcov(no3_tensor_mod$gam)[c(2,seq(38,54)), c(2,seq(38,54))]
# calculate all the variances for all the years i.e. var(x+y); should be 18 total entries
var_vector = c()
for (i in 2:18){
  var_vector[1] <- native_yr_vcov[1,1]
  var_vector[i] <- native_yr_vcov[1,1] + native_yr_vcov[i,i] + 2 * native_yr_vcov[i,1]
}
native_yr_vcov[1,1] + native_yr_vcov[2,2] + 2 * native_yr_vcov[2,1]

length(unique(native_yr_vcov))
sd_vector <- sqrt(var_vector)

#matrix with 19 cols for 19 years, three rows: one for effect estimate of total effect per year (total effect = main effect + interx effect), one for CI lower, one for CI upper
no3_decline_model_all <- data.frame()
no3_decline_model_all[1,1] <- summary(no3_tensor_mod$gam)$p.coeff[2] # county type main effect estimate (baseline year)
no3_decline_model_all[1,2] <- summary(no3_tensor_mod$gam)$p.coeff[2] - 1.96*sd_vector[1] # LL 95% CI
no3_decline_model_all[1,3] <- summary(no3_tensor_mod$gam)$p.coeff[2] + 1.96*sd_vector[1] # UL 95% CI

# fill in matrix thru loop for every following year
yr_ct <- 38
for (i in 2:18){
  no3_decline_model_all[i,1] <- summary(no3_tensor_mod$gam)$p.coeff[2]+
    summary(no3_tensor_mod$gam)$p.coeff[yr_ct]
  no3_decline_model_all[i,2] <- summary(no3_tensor_mod$gam)$p.coeff[2]+
    summary(no3_tensor_mod$gam)$p.coeff[yr_ct] - 1.96*sd_vector[i]
  no3_decline_model_all[i,3] <- summary(no3_tensor_mod$gam)$p.coeff[2]+
    summary(no3_tensor_mod$gam)$p.coeff[yr_ct] + 1.96*sd_vector[i]
  yr_ct <- yr_ct + 1
}
# set col names
colnames(no3_decline_model_all) <- c('estimate', 'cl_lower', 'cl_upper')
no3_decline_model_all$year <- seq(2000, 2017)

#PLOT OF TOTAL EFFECT OF NATIVE OVER TIME
modelsp_interx_plot <-ggplot() + 
  theme_linedraw() + 
  geom_line(data = no3_decline_model_all,
            aes(x=year, y = estimate)) +
  geom_line(data=no3_decline_model_all,
            aes(x=year, y=cl_lower), linetype = "dashed") +
    geom_line(data=no3_decline_model_all,
            aes(x=year, y=cl_upper), linetype = "dashed") +
  ylim(-0.5, 0.5) +
  # ggtitle(expression(paste("Modeled ", PM[2.5], " Difference in AI vs. Non-AI Populated Counties"))) +
  ylab(expression(paste("Mean Difference in ", NO[3]^{"-"}, " (", mu, "g/", m^3, ")"))) +
  xlab("Year") +
  theme(plot.title = element_text(size = 18),
        axis.title = element_text(size = 16),
        axis.text = element_text(size = 12),
        axis.title.x = element_blank(),
        # axis.title.y = element_blank()
        ) +
  guides(x =  guide_axis(angle = 45)) +
  scale_x_continuous(breaks = seq(2000,2018,1), expand = c(0, 0)) + 
  geom_hline(yintercept=0, linetype="solid", color = "red") 
modelsp_interx_plot
ggsave("../figures/effectmod_plots/sensitivity/spatial/no3_interx_t2_10knots.png")
```

##### set tensor term to 20 knots for lat and lon
Notes: 20 knots looks quite similar to 10 knots, so we went with 10 knots in the paper.

```{r run GAMM with 20 knots}
# Run GAMM with tensor smooth term
# no3_tensor_mod_20 =  gamm4(no3 ~ county_type*as.factor(year) + popd_q + hhinc_q
#                         + t2(lat, long, 
#                              k = c(20, 20),
#                              bs = 'cr'),
#                  random =~(1|State/GEOID),
#                  data = no3_lat_lon) # adjust to 20 knots

```

```{r plot changes in NO3 diff by county type over time}
# # vcov matrix
# native_yr_vcov <- vcov(no3_tensor_mod_20$gam)[c(2,seq(38,54)), c(2,seq(38,54))]
# # calculate all the variances for all the years i.e. var(x+y); should be 18 total entries
# var_vector = c()
# for (i in 2:18){
#   var_vector[1] <- native_yr_vcov[1,1]
#   var_vector[i] <- native_yr_vcov[1,1] + native_yr_vcov[i,i] + 2 * native_yr_vcov[i,1]
# }
# native_yr_vcov[1,1] + native_yr_vcov[2,2] + 2 * native_yr_vcov[2,1]
# 
# length(unique(native_yr_vcov))
# sd_vector <- sqrt(var_vector)
# 
# #matrix with 19 cols for 19 years, three rows: one for effect estimate of total effect per year (total effect = main effect + interx effect), one for CI lower, one for CI upper
# no3_decline_model_all <- data.frame()
# no3_decline_model_all[1,1] <- summary(no3_tensor_mod_20$gam)$p.coeff[2] # county type main effect estimate (baseline year)
# no3_decline_model_all[1,2] <- summary(no3_tensor_mod_20$gam)$p.coeff[2] - 1.96*sd_vector[1] # LL 95% CI
# no3_decline_model_all[1,3] <- summary(no3_tensor_mod_20$gam)$p.coeff[2] + 1.96*sd_vector[1] # UL 95% CI
# 
# # fill in matrix thru loop for every following year
# yr_ct <- 38
# for (i in 2:18){
#   no3_decline_model_all[i,1] <- summary(no3_tensor_mod_20$gam)$p.coeff[2]+
#     summary(no3_tensor_mod_20$gam)$p.coeff[yr_ct]
#   no3_decline_model_all[i,2] <- summary(no3_tensor_mod_20$gam)$p.coeff[2]+
#     summary(no3_tensor_mod_20$gam)$p.coeff[yr_ct] - 1.96*sd_vector[i]
#   no3_decline_model_all[i,3] <- summary(no3_tensor_mod_20$gam)$p.coeff[2]+
#     summary(no3_tensor_mod_20$gam)$p.coeff[yr_ct] + 1.96*sd_vector[i]
#   yr_ct <- yr_ct + 1
# }
# # set col names
# colnames(no3_decline_model_all) <- c('estimate', 'cl_lower', 'cl_upper')
# no3_decline_model_all$year <- seq(2000, 2017)
# 
# #PLOT OF TOTAL EFFECT OF NATIVE OVER TIME
# modelsp_interx_plot <-ggplot() + 
#   theme_linedraw() + 
#   geom_line(data = no3_decline_model_all,
#             aes(x=year, y = estimate)) +
#   geom_line(data=no3_decline_model_all,
#             aes(x=year, y=cl_lower), linetype = "dashed") +
#     geom_line(data=no3_decline_model_all,
#             aes(x=year, y=cl_upper), linetype = "dashed") +
#   ylim(-1, 1) +
#   # ggtitle(expression(paste("Modeled ", PM[2.5], " Difference in AI vs. Non-AI Populated Counties"))) +
#   ylab(expression(paste("Mean Difference in ", NO[3]^{"-"}, " (", mu, "g/", m^3, ")"))) +
#   xlab("Year") +
#   theme(plot.title = element_text(size = 18),
#         axis.title = element_text(size = 16),
#         axis.text = element_text(size = 12),
#         # axis.title.x = element_blank(),
#         # axis.title.y = element_blank()
#         ) +
#   guides(x =  guide_axis(angle = 45)) +
#   scale_x_continuous(breaks = seq(2000,2018,1), expand = c(0, 0)) + 
#   geom_hline(yintercept=0, linetype="solid", color = "red") 
# modelsp_interx_plot
# ggsave("../figures/effectmod_plots/sensitivity/spatial/no3_interx_t2_20.png")
```

# Spatial Lag Models (not using in our present analysis as of 11/1/22)
Get data in spatial df (nh4_sp), create Queen's contiguity spatial weights matrix (w, wm, rwm)

```{r read in spatial dataset, join with pm components data}
# 
# # read in sf counties file from tigris library; filter out HI, AK, territories
# library(tigris)
# us_counties = counties() %>% filter(STATEFP != "02" & STATEFP != "15" & STATEFP <= 56)
# us_counties
# # convert sf to spdf to join with PM df
# us_counties_sp = as_Spatial(us_counties)
# 
# # select only model pm2.5 data from 2000
# no3_2000 = no3 %>% filter(year == 2000)
# no3_2000
# 
# # join PM data with spatial dataset to create spatial df for 2000
# no3_2000_sp <- merge(us_counties_sp, no3_2000)
# 
# # create spatial weights matrix
# w_v2 <- poly2nb(no3_2000_sp, queen = TRUE)
# summary(w_v2)
# 
# anti_join(st_drop_geometry(us_counties), no3_2000) # check that they contain same counties (even if out of order)
# 
# # check on bordering counties of given county
# w_v2[[730]]
# no3_2000_sp$GEOID[730] # random county of interest: champaign county, OH
# no3_2000_sp$GEOID[c(516, 877, 925, 2510, 2768, 2993)] # check to see if they are actually bordering counties; they are
# 
# # convert to matrix and then listw format
# # zero.policy = T to include island counties (offshore, but still a part of contiguous US state)
# wm <- nb2mat(w_v2, style='B', zero.policy = TRUE)
# rwm <- mat2listw(wm, style='W')
```

## Run spatial diagnostics on non-spatial models
```{r OLS regression}
# fit_1 <- lm(no3 ~ county_type + popd_q + hhinc_q,
#             data=no3_2000_sp)
# summary(fit_1)
# 
# # check global moran's I test of residuals
# lm.morantest(fit_1, rwm, alternative="two.sided",  zero.policy = TRUE)
# 
# # check local moran's I test of residuals
# 
# # NOTES: Global Moran's I value is significant; should proceed with spatial model
# 
# # run lagrange test as diagnostic for SLM or SEM
# lm.LMtests(fit_1, rwm, test = c("LMerr","LMlag","RLMerr","RLMlag","SARMA"),
#            zero.policy = TRUE)
# # NOTES: All p-values are highly significant in the standard and robust tests, ie. both spatial lag and error LM are significant (can run either model)
```

```{r linear mixed effects regression, cache = TRUE}
# library(lme4)
# 
# # get lat lon of us county centroids (projection = NAD83)
# library(rgeos)
# us_counties = st_read("../data/cb_2018_us_county_500k/cb_2018_us_county_500k.shp") %>%
#   filter(STATEFP != "02" & STATEFP != "15" & STATEFP <= 56) #filter to 48 contiguous states
# # calculate centroid
# sf_centroid = st_centroid(us_counties)
# # plot
# ggplot() +
#   geom_sf(data = us_counties, fill = 'white') +
#   geom_sf(data = sf_centroid, color = 'red')
# sf_centroid
# 
# # join centroid point and model PM data!
# no3_sf = merge(sf_centroid, no3)
# 
# # separate x and y coordinates, append these columns to dataframe
# no3_sf = no3_sf %>%
#   mutate(x = st_coordinates(no3_sf)[,1],
#          y = st_coordinates(no3_sf)[,2])
# 
# # run linear random intercept model
# nre_fit = lmer(no3 ~ county_type * as.factor(year) +
#                     popd_q + 
#                     hhinc_q +
#                     (1|State/GEOID),
#                   data = no3, REML=FALSE)
# summary(nre_fit)
# residuals(nre_fit)
# # create column for residual values in model PM dataframe
# no3$lmerres = residuals(nre_fit)
# no3
```

```{r cache = TRUE}
# # Run local moran's I on residuals
# 
# # filter out df with lmer residuals to just 2017 values
# no3_17_res = no3 %>% filter(year == 2017)
# # join PM data with spatial dataset to create spatial df for 2017
# no3_2017_lmer_sp <- merge(us_counties_sp, no3_17_res)
# 
# # Local moran's I of lmer residuals
# moran.plot(no3_2017_lmer_sp$no3, rwm)
# 
# # calculate local moran's I test of residuals
# local_lmer_17 <- localmoran(x = no3_2017_lmer_sp$no3, listw = rwm)
# 
# # binds results to our polygon shapefile
# moran.map_lmer_17 <- cbind(no3_2017_lmer_sp, local_lmer_17)
# 
# class(moran.map_lmer_17)
# tm_shape(moran.map_lmer_17) +
#   tm_fill(col = "Ii", # local moran's I statistic values
#           style = "quantile",
#           title = "local moran statistic") 
```

```{r Map hot and cold spots based on local morans I, cache = TRUE}
# # scale PM2.5
# no3_2017_lmer_sp$s_pm25 = scale(no3_2017_lmer_sp$no3) %>% as.vector()
# 
# #create a spatial lag variable for scaled pm2.5 and save it to a new column
# no3_2017_lmer_sp$lag_s_pm25 <- lag.listw(rwm, no3_2017_lmer_sp$s_pm25) # use 'rwm' listw weights object specified above to create lagged vector
# summary(no3_2017_lmer_sp$s_pm25)
# summary(no3_2017_lmer_sp$lag_s_pm25)
# 
# x <- no3_2017_lmer_sp$s_pm25
# y <- no3_2017_lmer_sp$lag_s_pm25
# xx <- tibble(x,y)
# moran.plot(x, rwm) # same as scatterplot above (just rescaled)
# names(no3_2017_lmer_sp)
# no3_2017_lmer_sp$lmerres
# # add column to show LISA quadrants
# no3_2017_lmer_sf <- st_as_sf(no3_2017_lmer_sp) %>% 
#   mutate(quad_sig = ifelse(no3_2017_lmer_sp$s_pm25 > 0 & 
#                               no3_2017_lmer_sp$lag_s_pm25 > 0 & 
#                               local_lmer_17[,5] <= 0.05, 
#                      "high-high",
#                      ifelse(no3_2017_lmer_sp$s_pm25 <= 0 & 
#                               no3_2017_lmer_sp$lag_s_pm25 <= 0 & 
#                               local_lmer_17[,5] <= 0.05, 
#                      "low-low", 
#                      ifelse(no3_2017_lmer_sp$s_pm25 > 0 & 
#                               no3_2017_lmer_sp$lag_s_pm25 <= 0 & 
#                               local_lmer_17[,5] <= 0.05, 
#                      "high-low",
#                      ifelse(no3_2017_lmer_sp$s_pm25 <= 0 & 
#                               no3_2017_lmer_sp$lag_s_pm25 > 0 & 
#                               local_lmer_17[,5] <= 0.05,
#                      "low-high", 
#                      "non-significant")))))
# table(no3_2017_lmer_sf$quad_sig)
# 
# # check that all h-h l-l from table() sum up to all significant counties
# nrow(local_lmer_17[local_lmer_17[,5] <= 0.05,])
# 
# qtm(no3_2017_lmer_sf, fill="quad_sig", fill.title="LISA")

```

```{r}
# # DUMMY CODE: calculate moran's I
# library(DHARMa)
# # It's a good idea to use a RE to take out the cluster effects. This accounts
# # for the autocorrelation within clusters 
# 
# # DHARMa default is to re-simulted REs - this means spatial pattern remains
# # because residuals are still clustered
# 
# res = simulateResiduals(nre_fit)
# # testSpatialAutocorrelation(res, x =  no3_sf$x, y = no3_sf$y) DOESN'T WORK, need to group by county to account for clustering within county over time
# 
# # However, it should disappear if you just calculate an aggregate residuals per cluster
# # Because at least how the data are simulated, cluster are spatially independent
# # Group by County
# res2 = recalculateResiduals(res, group = no3_sf$GEOID)
# testSpatialAutocorrelation(res2, 
#                            x =  aggregate(no3_sf$x, list(no3_sf$GEOID), mean)$x, 
#                            y = aggregate(no3_sf$y, list(no3_sf$GEOID), mean)$x)
# # Group by State
# res3 = recalculateResiduals(res, group = no3_sf$STATEFP)
# testSpatialAutocorrelation(res3, 
#                            x =  aggregate(no3_sf$x, list(no3_sf$STATEFP), mean)$x, 
#                            y = aggregate(no3_sf$y, list(no3_sf$STATEFP), mean)$x)
# 
# ## Conclusion, most counties are not spatially independent (significant moran's I values prevalent)
```

## Spatial Models using spatial reg package

```{r spatial lag model}
# library(spatialreg)
# fit_1_lag <- lagsarlm(no3 ~ county_type + popd_q + hhinc_q,
#             data=no3_2000_sp, rwm, zero.policy = TRUE)
# summary(fit_1_lag)
```

```{r spatial error model}
# fit_1_err <- errorsarlm(no3 ~ county_type + popd_q + hhinc_q,
#                         data=no3_2000_sp, rwm, zero.policy = TRUE)
# summary(fit_1_err)

```

## Spatial Models using splm package

```{r "transform data frame into panel data"}
# library(plm)
# 
# # convert df to panel dataframe
# p.data = pdata.frame(no3, index = c("GEOID", "year"))
# p.data

# # run splm model with queen's contiguity matrix, KKP specified random effects
# no3_nrelag = spml(no3 ~ county_type + popd_q + hhinc_q + year,
#                          data = p.data,
#                          index = c("GEOID", "year"),
#                          listw = rwm,
#                          model = "random",
#                          effect = "individual",
#                          lag = T,
#                          spatial.error = "kkp",
#                          zero.policy = TRUE)
# summary(no3_nrelag)
# 
# # save model output to intermediate folder
# saveRDS(no3_nrelag, file = "intermediate/spatial_models/splag_re_kkp_model.rds")

# # run splm model with queen's contiguity matrix, Baltagi specified random effects
# no3_nrelag_b = spml(no3 ~ county_type + popd_q + hhinc_q + year,
#                          data = p.data,
#                          index = c("GEOID", "year"),
#                          listw = rwm,
#                          model = "random",
#                          effect = "individual",
#                          lag = T,
#                          spatial.error = "kkp",
#                          zero.policy = TRUE)
# summary(no3_nrelag_b)
# 
# # save model output to intermediate folder
# saveRDS(no3_nrelag_b, file = "intermediate/spatial_models/splag_re_b_model.rds")

```

### Run spatial and non-spatial models; examine only recent years, after 2015

```{r}
# # convert df to panel dataframe
# no3_2015.2019 = no3 %>% filter(year >= 2015)
# p.data.2015.2019 = pdata.frame(no3_2015.2019, index = c("GEOID", "year"))
# p.data.2015.2019
# 
# lme_2015.2019 <- lmer(no3 ~ county_type + year +
#                     popd_q + 
#                     hhinc_q +
#                     county_type*year +
#                     (1|State/GEOID),
#                   data = no3_2015.2019, REML=FALSE)
# summary(lme_2015.2019)

# run splm model with queen's contiguity matrix, KKP specified random effects
# no3_kkp_2015.2019 = spml(no3 ~ county_type*year + popd_q + hhinc_q,
#                          data = p.data.2015.2019,
#                          index = c("GEOID", "year"),
#                          listw = rwm,
#                          model = "random",
#                          effect = "individual",
#                          lag = T,
#                          spatial.error = "kkp",
#                          zero.policy = TRUE)
# summary(no3_kkp_2015.2019)

```


### All Years: Run nonspatial and spatial models
#### Non spatial model
```{r}
# no3_lme <- lmer(no3 ~ county_type*as.factor(year) +
#                     popd_q + 
#                     hhinc_q +
#                     (1|State/GEOID),
#                   data = no3, REML=FALSE)
# summary(no3_lme)
# dim(model.matrix(no3_lme)) 
```
#### Spatial models (w/ contiguity based spatial weights matrix)

##### Without interX
```{r cache = TRUE}
# # run splm model with queen's contiguity matrix, KKP specified random effects
# no3_kkp = spml(no3 ~ county_type + year + popd_q + hhinc_q,
#                          data = p.data,
#                          index = c("GEOID", "year"),
#                          listw = rwm,
#                          model = "random",
#                          effect = "individual",
#                          lag = T,
#                          spatial.error = "kkp",
#                          zero.policy = TRUE)
# summary(no3_kkp)
# 
# # splag = readRDS("intermediate/spatial_models/splag_re_b_model.rds")
# # splag
```


##### With interX
```{r cache = TRUE}
# # run splm model with queen's contiguity matrix, KKP specified random effects, interX between county type and year
# # V1
# no3_kkp_interx = spml(no3 ~ county_type*year + popd_q + hhinc_q,
#                          data = p.data,
#                          index = c("GEOID", "year"),
#                          listw = rwm,
#                          model = "random",
#                          effect = "individual",
#                          lag = T,
#                          spatial.error = "kkp",
#                          zero.policy = TRUE)
# summary(no3_kkp_interx)

```

```{r}
# data("Produc", package = "Ecdat")
# class(Produc)
# class(p.data)
# data("usaww")
```


```{r run spml on simple df instead of panel df}
# no3_kkp_interx_df = spml(no3 ~ county_type*year + popd_q + hhinc_q,
#                          data = no3,
#                          index = c("GEOID", "year"),
#                          listw = rwm,
#                          model = "random",
#                          effect = "individual",
#                          lag = T,
#                          spatial.error = "kkp",
#                          zero.policy = TRUE)
# summary(no3_kkp_interx_df)
```


```{r cache = TRUE}
# # V2
# no3_kkp_interx_v2 = spml(no3 ~ county_type*year + popd_q + hhinc_q,
#                          data = p.data,
#                          index = c("year", "GEOID"), # reverse this from V1 above
#                          listw = rwm,
#                          model = "random",
#                          effect = "individual",
#                          lag = T,
#                          spatial.error = "kkp",
#                          zero.policy = TRUE)
# summary(no3_kkp_interx_v2)
```


###### Difference in time trends plot
```{r}
# # vcov matrix
# native_yr_vcov <- vcov(no3_kkp_interx)[c(2,seq(38,54)), c(2,seq(38,54))]
# # calculate all the variances for all the years i.e. var(x+y); should be 18 total entries
# var_vector = c()
# for (i in 2:18){
#   var_vector[1] <- native_yr_vcov[1,1]
#   var_vector[i] <- native_yr_vcov[1,1] + native_yr_vcov[i,i] + 2 * native_yr_vcov[i,1]
# }
# native_yr_vcov[1,1] + native_yr_vcov[2,2] + 2 * native_yr_vcov[2,1]
# length(unique(native_yr_vcov))
# sd_vector <- sqrt(var_vector)
# 
# #matrix with 19 cols for 19 years, three rows: one for effect estimate of total effect per year (total effect = main effect + interx effect), one for CI lower, one for CI upper
# no3_decline_model_all <- data.frame()
# no3_decline_model_all[1,1] <- summary(no3_kkp_interx)$coefficients[2] # county type main effect estimate (baseline year)
# no3_decline_model_all[1,2] <- summary(no3_kkp_interx)$coefficients[2] - 1.96*sd_vector[1] # LL 95% CI
# no3_decline_model_all[1,3] <- summary(no3_kkp_interx)$coefficients[2] + 1.96*sd_vector[1] # UL 95% CI
# names(summary(no3_kkp_interx))
# summary(no3_kkp_interx)
# 
# # fill in matrix thru loop for every following year
# yr_ct <- 38
# for (i in 2:18){
#   no3_decline_model_all[i,1] <- summary(no3_kkp_interx)$coefficients[2]+
#     summary(no3_kkp_interx)$coefficients[yr_ct]
#   no3_decline_model_all[i,2] <- summary(no3_kkp_interx)$coefficients[2]+
#     summary(no3_kkp_interx)$coefficients[yr_ct] - 1.96*sd_vector[i]
#   no3_decline_model_all[i,3] <- summary(no3_kkp_interx)$coefficients[2]+
#     summary(no3_kkp_interx)$coefficients[yr_ct] + 1.96*sd_vector[i]
#   yr_ct <- yr_ct + 1
# }
# # set col names
# colnames(no3_decline_model_all) <- c('estimate', 'cl_lower', 'cl_upper')
# no3_decline_model_all$year <- seq(2000, 2017)
# 
# #PLOT OF TOTAL EFFECT OF NATIVE OVER TIME
# modelsp_interx_plot <-ggplot() + 
#   theme_linedraw() + 
#   geom_line(data = no3_decline_model_all,
#             aes(x=year, y = estimate)) +
#   geom_line(data=no3_decline_model_all,
#             aes(x=year, y=cl_lower), linetype = "dashed") +
#     geom_line(data=no3_decline_model_all,
#             aes(x=year, y=cl_upper), linetype = "dashed") +
#   ylim(-1, 0.5) +
#   # ggtitle(expression(paste("Modeled ", PM[2.5], " Difference in AI vs. Non-AI Populated Counties"))) +
#   ylab(expression(paste("Mean Difference in ", NO[3]^{"-"}, " (", mu, "g/", m^3, ")"))) +
#   xlab("Year") +
#   theme(plot.title = element_text(size = 18),
#         axis.title = element_text(size = 16),
#         axis.text = element_text(size = 12),
#         # axis.title.x = element_blank(),
#         # axis.title.y = element_blank()
#         ) +
#   guides(x =  guide_axis(angle = 45)) +
#   scale_x_continuous(breaks = seq(2000,2018,1), expand = c(0, 0)) + 
#   geom_hline(yintercept=0, linetype="solid", color = "red") 
# modelsp_interx_plot
# ggsave("../figures/effectmod_plots/sensitivity/spatial/no3_interx_spatial.png")
```

#### Spatial models (w/ distance based spatial weights matrix)

```{r}
# # create distance based matrix
# library(fields)
# no3_2000_sp
# mycoords <- coordinates(no3_2000_sp) # creates xy coords of all 3107 counties
# length(mycoords)                         # should be 6214 (3107*2)
# mydm <- rdist.earth(mycoords)            # computes distance in miles!
# for(i in 1:dim(mydm)[1]) {mydm[i,i] = 0} # renders exactly zero all diagonal elements
# mydm[mydm > 1000] <- 0                   # all distances > 1000 miles are set to zero
# mydm <- ifelse(mydm!=0, 1/mydm, mydm)    # inverting distances
# mydm.lw <- mat2listw(mydm, style="W")    # create a (normalized) listw object
# mydmi <- listw2mat(mydm.lw)              # change back to 'classic' matrix, if desired
# View(mydm.lw)
# 
# w_v2[[730]]
# no3_2000_sp$GEOID[730]
# no3_2000_sp$GEOID[c(334, 1668, 1680, 1851, 1901, 2099, 2657)]
# 
# # run spatial model with inverse distance based matrix
# no3_kkp_interx_idm = spml(no3 ~ county_type*year + popd_q + hhinc_q,
#                          data = p.data,
#                          index = c("year", "GEOID"), # reverse this from V1 above
#                          listw = mydm.lw,
#                          model = "random",
#                          effect = "individual",
#                          lag = T,
#                          spatial.error = "kkp",
#                          zero.policy = TRUE)
# summary(no3_kkp_interx_idm)
```